---
type: slides
---

# Model Selection

---


# Model Selection

In practice, the model we should consider to describe a specific time series is generally unknown. For example, if we consider a time series issued from the model ` WN() + AR1() + RW()`, the WV of this time series may not clearly indicate which model should be used. Here is an example:

```r
library(gmwm)
# Set seed to repliacte results
set.seed(182)

# Sample size
n = 4*10^4

# Specify model
model = AR1(phi = .9, sigma2 = .1) + WN(sigma2 = 1) + RW(gamma2 = 0.0001)

# Generate Data
Xt = gen_gts(n = n, model = model)

```

---


```r
# Plot WV
plot(wvar(Xt))
```

<div style="text-align:center"><img src="gmwm18-1.png" alt=" " width="100%">

---

Assuming that once the correct model is identified, we obtain the following result:

```r
# Fit true model
mod = gmwm(WN() + AR1() + RW(), Xt)
summary(mod, inference = TRUE)       
```

```out
## Model Information: 
##           Estimates       CI Low      CI High           SE
## WN     0.9851106066 9.697094e-01 1.0005118562 9.363295e-03
## AR1    0.9009999310 8.951125e-01 0.9068873450 3.579294e-03
## SIGMA2 0.0959828526 8.993792e-02 0.1020277806 3.675055e-03
## RW     0.0001174386 8.669134e-05 0.0001481859 1.869301e-05
## 
## * The initial values of the parameters used in the minimization of the GMWM objective function 
##   were generated by the program underneath seed: 1337. 
## 
## Objective Function: 0.0174
## 
## Asymptotic Goodness of Fit: 
## Test Statistic: 24.48 on 11 degrees of freedom
## The resulting p-value is: 0.0108

```

---

```r
plot(mod)     
```

<div style="text-align:center"><img src="gmwm19-1.png" alt=" " width="100%">


---

We could then wonder if a *simpler* model might be more appropriate (e.g. `WN() + AR1()`). To avoid any numerical issues we initialize the next model using the parameter values obtained from the previous estimation:

```r
mod1_start = WN(sigma2 = 0.990997918) + AR1(phi = 0.897352858, sigma2 = 0.100979984)
mod1 = gmwm(mod1_start, Xt)
summary(mod1, inference = TRUE)    
```

```out
## Model Information: 
##         Estimates     CI Low    CI High          SE
## WN     0.98751805 0.97321613 1.00181998 0.008694951
## AR1    0.90521353 0.89965848 0.91076857 0.003377228
## SIGMA2 0.09392203 0.08830933 0.09953472 0.003412276
## 
## * The initial values of the parameters used in the minimization of the GMWM objective function 
##   were given by YOU! 
## 
## Objective Function: 0.6276
## 
## Asymptotic Goodness of Fit: 
## Test Statistic: 1612426.45 on 12 degrees of freedom
## The resulting p-value is: 0
```

---

```r
plot(mod1)     
```

<div style="text-align:center"><img src="gmwm20-1.png" alt=" " width="100%">

---

The second model appears to provide a poorer fit then our first (correct) model. We can further compare these models as follows:

```r
compare_models(mod, mod1, show.theo.wv = T,   
               facet.label = c('WN() + AR1() + RW()', 'WN() + AR1()'))
```
<div style="text-align:center"><img src="gmwm21-1.png" alt=" " width="75%">

---

The `gmwm` package also contains a method to select and rank models automatically, either by providing a list of models or searching all possibilities within *nested* models. We will use the second method and search all possible models within the nested model `WN() + AR1() + RW()`; namely the following seven models:

- `WN()`
- `AR1()`
- `RW()`
- `WN() + AR1()`
- `WN() + RW()`
- `AR1() + RW()`
- `WN() + AR1() + RW()`


---

This method selection approach is implemented in the function `rank_models()`, which is used in the example below:

```{r, cache=TRUE}
rank_models(WN() + AR1() + RW(), data = Xt, nested = TRUE, bootstrap = TRUE, B = 100)
```

```out
## The model ranking is given as: 
##                Obj Fun Optimism Criterion GoF P-Value
## 1. WN AR1 RW    0.0174   0.4030    0.4203        1.00
## 2. AR1 RW      48.3284   0.2300   48.5583        0.00
## 3. AR1         52.1805   0.1688   52.3493        0.07
## 4. WN AR1      52.1703   0.1809   52.3511        0.03
## 5. WN RW       77.2516   0.3091   77.5607        0.06
## 6. WN          82.4863   0.1150   82.6013        0.06
## 7. RW        1290.6724   0.0109 1290.6833        0.00

```

---

In this case, the model `WN() + AR1() + RW()` appears to provide the best fit among all candidate models. However, this example is bit artificial as the correct model is used as reference. One could wonder what would happen if we specified an *incorrect* model to the function `rank_models()`. This is shown in a following example that suggest the model `WN() + 2*AR1() + RW()` which is clearly not the right one:

---

```{r, cache=TRUE}
rank_models(WN() + 2*AR1() + RW(), data = Xt, nested = TRUE, bootstrap = TRUE, B = 100)
```

```out
## The model ranking is given as: 
##                    Obj Fun Optimism Criterion GoF P-Value
## 1. WN AR1 AR1       0.0365   0.2682    0.3047        0.90
## 2. WN AR1 RW        0.0174   0.4030    0.4203        1.00
## 3. WN AR1 AR1 RW    0.0143   0.4425    0.4568        0.99
## 4. AR1 AR1 RW       0.3092   0.4336    0.7429        0.48
## 5. AR1 AR1         47.8504   0.3694   48.2198        0.01
## 6. AR1 RW          48.3284   0.2300   48.5583        0.00
## 7. AR1             52.1805   0.1688   52.3493        0.07
## 8. WN AR1          52.1703   0.1809   52.3511        0.03
## 9. WN RW           77.2516   0.3091   77.5607        0.06
## 10. WN             82.4863   0.1150   82.6013        0.06
## 11. RW           1290.6724   0.0109 1290.6833        0.00
```


---

In this case also the suggested model remains the correct model, i.e. `WN() + AR1() + RW()`. However, this method selection approach is mainly indicative and more research is needed on the reliability of this method. In fact, all models having a Goodness-of-Fit (GoF) P-Values larger than, say, 5% should be considered as viable models. A possible approach is to select the model with the smallest number of parameters within these set of models having a GoF P-Values larger than 5%. In this case, the set of models is:

- \\(\mathcal{M}_1\\): `WN + AR1 + RW`
- \\(\mathcal{M}_2\\): `WN + 2*AR1`
- \\(\mathcal{M}_3\\): `WN + 2*AR1 + RW`
- \\(\mathcal{M}_4\\): `2*AR1 + RW`,

---

also leading to the choice of the model `WN + AR1 + RW` (since it has the smallest number of parameters). Finally, we could also compare these models graphically as follows:

```r
# Models to be compared
mod1 = gmwm(WN() + AR1() + RW(), Xt)
mod2 = gmwm(WN() + 2*AR1(), Xt)
mod3 = gmwm(WN() + 2*AR1() + RW(), Xt)
mod4 = gmwm(2*AR1() + RW(), Xt)
```

---

```r
# Compare models graphically
compare_models(mod1, mod2, mod3, mod4, show.theo.wv = T,   
               facet.label = c('M1', 'M2', 'M3', 'M4'))
```

<div style="text-align:center"><img src="gmwm22-1.png" alt=" " width="80%">


---

It can clearly be observed that all models provide extremely similar fits and using the "smallest" (i.e. `M1` - `WN() + AR1() + RW()`) appears reasonable.

---
